{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.feature = nn.Sequential(\n",
    "#             nn.Linear(3 * 28*28, 100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(100, 100),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.classifier = nn.Linear(100, num_classes)\n",
    "\n",
    "#     def forward(self, x, return_feat=False):\n",
    "#         x = x.view(x.size(0), -1) / 255\n",
    "#         intermediate_feats = []\n",
    "#         feat = x = self.feature[0](x)\n",
    "#         intermediate_feats.append(feat)\n",
    "\n",
    "#         for i in range(1, len(self.feature)):\n",
    "#             feat = x = self.feature[i](x)\n",
    "#             intermediate_feats.append(feat)\n",
    "\n",
    "#         x = self.classifier(x)\n",
    "\n",
    "#         if return_feat:\n",
    "#             return x, intermediate_feats\n",
    "#         else:\n",
    "#             return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Signal is Harder to Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(3 * 28*28, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x, return_feat=False):\n",
    "        x = x.view(x.size(0), -1)# / 255\n",
    "        feat = x = self.feature(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        if return_feat:\n",
    "            return x, feat\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "tensor([0.0000, 0.1412, 0.0000, 0.0561, 0.0000, 0.0506, 0.1033, 0.0000, 0.0323,\n",
      "        0.0000, 0.0000, 0.0000, 0.1016, 0.0108, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.1051, 0.0129, 0.0000, 0.0000, 0.0000, 0.0867, 0.1257, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0784, 0.0347, 0.0000, 0.1108, 0.0000, 0.1029, 0.0711,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1244, 0.0000, 0.0000, 0.1249, 0.0214,\n",
      "        0.2292, 0.2672, 0.0072, 0.0028, 0.0504, 0.1563, 0.0000, 0.0000, 0.1711,\n",
      "        0.0599, 0.0000, 0.0000, 0.0503, 0.0000, 0.1525, 0.1054, 0.2352, 0.0858,\n",
      "        0.0292, 0.0000, 0.1643, 0.1247, 0.0901, 0.0000, 0.0000, 0.0508, 0.2688,\n",
      "        0.1311, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451, 0.1349, 0.0506,\n",
      "        0.0856, 0.0313, 0.0927, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.1630,\n",
      "        0.0154, 0.0166, 0.0000, 0.0039, 0.0000, 0.0775, 0.0800, 0.0035, 0.1151,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.1166, 0.0688, 0.0000, 0.0614, 0.0000, 0.0000, 0.0404, 0.0269, 0.0986,\n",
      "        0.0000, 0.0542, 0.0000, 0.1117, 0.0929, 0.0000, 0.0000, 0.0366, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1450, 0.1201, 0.0027, 0.0000, 0.0189,\n",
      "        0.0000, 0.0389, 0.0373, 0.0000, 0.0285, 0.1176, 0.0000, 0.1259, 0.0583,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0149, 0.0000, 0.0000, 0.2480, 0.1901,\n",
      "        0.0390, 0.2154, 0.0000, 0.0852, 0.2062, 0.0278, 0.0000, 0.0000, 0.1589,\n",
      "        0.0000, 0.0000, 0.0000, 0.1108, 0.0000, 0.3525, 0.2088, 0.2396, 0.1543,\n",
      "        0.0000, 0.0016, 0.1742, 0.1576, 0.0082, 0.0000, 0.0000, 0.1581, 0.1435,\n",
      "        0.1203, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0663, 0.0983, 0.0427,\n",
      "        0.1449, 0.0038, 0.0013, 0.0443, 0.0000, 0.0000, 0.0000, 0.0000, 0.1222,\n",
      "        0.0000, 0.0000, 0.0271, 0.0000, 0.0000, 0.1114, 0.0451, 0.0000, 0.0000,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0297, 0.2232, 0.0000, 0.0943, 0.0000, 0.0752, 0.0000, 0.0000, 0.0000,\n",
      "        0.0805, 0.0000, 0.0000, 0.0675, 0.1355, 0.0000, 0.0930, 0.0055, 0.0000,\n",
      "        0.0400, 0.0000, 0.0000, 0.0000, 0.1042, 0.0473, 0.1390, 0.0443, 0.0000,\n",
      "        0.1114, 0.0539, 0.1455, 0.0000, 0.0315, 0.0000, 0.0761, 0.0948, 0.1511,\n",
      "        0.0000, 0.0000, 0.0403, 0.0000, 0.0000, 0.0000, 0.0257, 0.1770, 0.0000,\n",
      "        0.2885, 0.3653, 0.0000, 0.0203, 0.1890, 0.0007, 0.0000, 0.0000, 0.2391,\n",
      "        0.0000, 0.0336, 0.0000, 0.1849, 0.0000, 0.1948, 0.0414, 0.1393, 0.0000,\n",
      "        0.0000, 0.1255, 0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0729, 0.1069,\n",
      "        0.1996, 0.0000, 0.0000, 0.0000, 0.0026, 0.0000, 0.1172, 0.2044, 0.0000,\n",
      "        0.0327, 0.0000, 0.0000, 0.2939, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1213, 0.0000, 0.0000, 0.0000, 0.2765, 0.0583, 0.0209, 0.0058,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0060, 0.0429, 0.0350, 0.0000, 0.0000, 0.0000, 0.0144, 0.0389, 0.0000,\n",
      "        0.1180, 0.0579, 0.0246, 0.0716, 0.0604, 0.0038, 0.0000, 0.0808, 0.0000,\n",
      "        0.0000, 0.0000, 0.0083, 0.0849, 0.1198, 0.0625, 0.0464, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0024, 0.0000, 0.0947, 0.0797, 0.0000, 0.0410, 0.0581,\n",
      "        0.0345, 0.0000, 0.0000, 0.0094, 0.0731, 0.0000, 0.0000, 0.1452, 0.0816,\n",
      "        0.1157, 0.1916, 0.0000, 0.0449, 0.2243, 0.0100, 0.0000, 0.0000, 0.3075,\n",
      "        0.0000, 0.0000, 0.0000, 0.1194, 0.0000, 0.2327, 0.0811, 0.1149, 0.1294,\n",
      "        0.0000, 0.0000, 0.1583, 0.0032, 0.0343, 0.0000, 0.0000, 0.0600, 0.0790,\n",
      "        0.1461, 0.0000, 0.0000, 0.0228, 0.0622, 0.0000, 0.0820, 0.0383, 0.0320,\n",
      "        0.1085, 0.0000, 0.0422, 0.1614, 0.0000, 0.0000, 0.0000, 0.0000, 0.1888,\n",
      "        0.0000, 0.0683, 0.0305, 0.0000, 0.0000, 0.0818, 0.0771, 0.0000, 0.0000,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.1800, 0.0297, 0.0000, 0.0180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0250,\n",
      "        0.0201, 0.0000, 0.0243, 0.1110, 0.2779, 0.0228, 0.0076, 0.0329, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.2486, 0.1419, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0017, 0.0120, 0.0000, 0.0000, 0.0636, 0.0305, 0.0289, 0.0567,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0108, 0.0000, 0.2967, 0.1009,\n",
      "        0.0371, 0.2868, 0.0000, 0.1109, 0.1929, 0.0844, 0.0000, 0.0000, 0.1372,\n",
      "        0.0000, 0.0129, 0.0000, 0.1642, 0.0000, 0.3685, 0.0955, 0.2080, 0.0828,\n",
      "        0.0000, 0.0000, 0.2667, 0.0527, 0.0308, 0.0000, 0.0000, 0.0786, 0.0876,\n",
      "        0.1559, 0.0000, 0.0188, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.0400,\n",
      "        0.1600, 0.0116, 0.0000, 0.0209, 0.0000, 0.0000, 0.0000, 0.0000, 0.0122,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0210, 0.0597, 0.0000,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0383, 0.0000, 0.0000, 0.0653, 0.0000, 0.0210, 0.0289, 0.0000, 0.1260,\n",
      "        0.0000, 0.0248, 0.0000, 0.1159, 0.1477, 0.0000, 0.0268, 0.0138, 0.0000,\n",
      "        0.0783, 0.0000, 0.0000, 0.0000, 0.2316, 0.0933, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0777, 0.0982, 0.0000, 0.0382, 0.0721, 0.0000, 0.1403, 0.0204,\n",
      "        0.1095, 0.0000, 0.0000, 0.0000, 0.0346, 0.0000, 0.0000, 0.2594, 0.1079,\n",
      "        0.0353, 0.2139, 0.0000, 0.1692, 0.2234, 0.0585, 0.0000, 0.0000, 0.1681,\n",
      "        0.0000, 0.0283, 0.0000, 0.1043, 0.0000, 0.3179, 0.1903, 0.1426, 0.1032,\n",
      "        0.0000, 0.0000, 0.2222, 0.0000, 0.0291, 0.0286, 0.0000, 0.1595, 0.1004,\n",
      "        0.1251, 0.0000, 0.0015, 0.0017, 0.0465, 0.0000, 0.0822, 0.2197, 0.0000,\n",
      "        0.1542, 0.0000, 0.0058, 0.1293, 0.0000, 0.0932, 0.0000, 0.0000, 0.1479,\n",
      "        0.0000, 0.0000, 0.1099, 0.0070, 0.0000, 0.1476, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "input_data = torch.randn(16, 3, 28, 28)\n",
    "outputs, intermediate_features = model(input_data, return_feat=True)\n",
    "# print(outputs.shape)\n",
    "# shape of feature map\n",
    "print(intermediate_features[0].shape)\n",
    "print(intermediate_features[1].shape) # After ReLU\n",
    "print(intermediate_features[2].shape)\n",
    "print(intermediate_features[3].shape) # After ReLU\n",
    "print(intermediate_features[4].shape)\n",
    "print(intermediate_features[5].shape) # After ReLU\n",
    "\n",
    "\n",
    "\n",
    "print(intermediate_features[0])\n",
    "print(intermediate_features[1]) # After ReLU\n",
    "print(intermediate_features[2])\n",
    "print(intermediate_features[3]) # After ReLU\n",
    "print(intermediate_features[4])\n",
    "print(intermediate_features[5]) # After ReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "input_data = torch.randn(16, 3, 28, 28)\n",
    "outputs, intermediate_features = model(input_data, return_feat=True)\n",
    "\n",
    "# Print intermediate features\n",
    "for i, feat in enumerate(intermediate_features):\n",
    "    print(f\"Intermediate feature {i + 1}: {feat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def main():\n",
    "    rand_data = torch.randn(16,1000)\n",
    "\n",
    "    #use same data for both the distributions\n",
    "    a = Variable(rand_data)\n",
    "    b = Variable(rand_data)\n",
    "\n",
    "    a_sm = F.softmax(a,dim=1)\n",
    "    b_sm = F.softmax(b,dim=1)\n",
    "\n",
    "    criterion = nn.KLDivLoss()\n",
    "\n",
    "    loss = criterion(a_sm,b_sm)\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
