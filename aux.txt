conda deactivate
source /home/rajeev/rrd/lff_env/bin/activate

wfe

python3 train_CIFAR_Resnet_1.py with server_user corrupted_cifar10 type1 skewed3 severity4 lambda_ortho=0.01



import sys
def calculate_cos_sim(model_b, model_d, layer_names):
    p11 = list(model_b.parameters())
    print(f'p11: {p11[2]}')
    p22 = list(model_d.parameters())
    cos_sim = 0.0
    for i in layer_names:
            p111 = p11[i].view(p11[i].size(0), -1)
            p222 = p22[i].view(p22[i].size(0), -1)
            sim = F.cosine_similarity(p111, p222)
            cos_sim += sim.mean(0)
    return cos_sim






Resnet20

layer name: fc.weight
layer name: fc.bias
layer name: conv1.weight
layer name: bn1.weight
layer name: bn1.bias
layer name: layer1.0.conv1.weight
layer name: layer1.0.bn1.weight
layer name: layer1.0.bn1.bias
layer name: layer1.0.conv2.weight
layer name: layer1.0.bn2.weight
layer name: layer1.0.bn2.bias
layer name: layer1.1.conv1.weight
layer name: layer1.1.bn1.weight
layer name: layer1.1.bn1.bias
layer name: layer1.1.conv2.weight
layer name: layer1.1.bn2.weight
layer name: layer1.1.bn2.bias
layer name: layer2.0.conv1.weight
layer name: layer2.0.bn1.weight
layer name: layer2.0.bn1.bias
layer name: layer2.0.conv2.weight
layer name: layer2.0.bn2.weight
layer name: layer2.0.bn2.bias
layer name: layer2.0.downsample.0.weight
layer name: layer2.0.downsample.1.weight
layer name: layer2.0.downsample.1.bias
layer name: layer2.1.conv1.weight
layer name: layer2.1.bn1.weight
layer name: layer2.1.bn1.bias
layer name: layer2.1.conv2.weight
layer name: layer2.1.bn2.weight
layer name: layer2.1.bn2.bias
layer name: layer3.0.conv1.weight
layer name: layer3.0.bn1.weight
layer name: layer3.0.bn1.bias
layer name: layer3.0.conv2.weight
layer name: layer3.0.bn2.weight
layer name: layer3.0.bn2.bias
layer name: layer3.0.downsample.0.weight
layer name: layer3.0.downsample.1.weight
layer name: layer3.0.downsample.1.bias
layer name: layer3.1.conv1.weight
layer name: layer3.1.bn1.weight
layer name: layer3.1.bn1.bias
layer name: layer3.1.conv2.weight
layer name: layer3.1.bn2.weight
layer name: layer3.1.bn2.bias
layer name: layer4.0.conv1.weight
layer name: layer4.0.bn1.weight
layer name: layer4.0.bn1.bias
layer name: layer4.0.conv2.weight
layer name: layer4.0.bn2.weight
layer name: layer4.0.bn2.bias
layer name: layer4.0.downsample.0.weight
layer name: layer4.0.downsample.1.weight
layer name: layer4.0.downsample.1.bias
layer name: layer4.1.conv1.weight
layer name: layer4.1.bn1.weight
layer name: layer4.1.bn1.bias
layer name: layer4.1.conv2.weight
layer name: layer4.1.bn2.weight
layer name: layer4.1.bn2.bias



layer name: conv1.weight

layer name: layer1.0.conv1.weight
layer name: layer1.0.conv2.weight
layer name: layer1.1.conv1.weight
layer name: layer1.1.conv2.weight # 

layer name: layer2.0.conv1.weight
layer name: layer2.0.conv2.weight
layer name: layer2.1.conv1.weight
layer name: layer2.1.conv2.weight # 

layer name: layer3.0.conv1.weight
layer name: layer3.0.conv2.weight
layer name: layer3.1.conv1.weight
layer name: layer3.1.conv2.weight

layer name: layer4.0.conv1.weight
layer name: layer4.0.conv2.weight
layer name: layer4.1.conv1.weight
layer name: layer4.1.conv2.weight





#-------------------------------------------------------#
Resnet_1: layer1.1.conv2.weight layer2.1.conv2.weight
Resnet_2: layer2.1.conv2.weight layer3.1.conv2.weight
Resnet_3: layer3.1.conv2.weight layer4.1.conv2.weight
Resnet_4: layer4.1.conv2.weight layer1.1.conv2.weight
#-------------------------------------------------------#

















param size: torch.Size([64, 3, 7, 7])
param size: torch.Size([64])
param size: torch.Size([64])
param size: torch.Size([64, 64, 3, 3])
param size: torch.Size([64])
param size: torch.Size([64])
param size: torch.Size([64, 64, 3, 3])
param size: torch.Size([64])
param size: torch.Size([64])
param size: torch.Size([64, 64, 3, 3])
param size: torch.Size([64])
param size: torch.Size([64])
param size: torch.Size([64, 64, 3, 3])
param size: torch.Size([64])
param size: torch.Size([64])
param size: torch.Size([128, 64, 3, 3])
param size: torch.Size([128])
param size: torch.Size([128])
param size: torch.Size([128, 128, 3, 3])
param size: torch.Size([128])
param size: torch.Size([128])
param size: torch.Size([128, 64, 1, 1])
param size: torch.Size([128])
param size: torch.Size([128])
param size: torch.Size([128, 128, 3, 3])
param size: torch.Size([128])
param size: torch.Size([128])
param size: torch.Size([128, 128, 3, 3])
param size: torch.Size([128])
param size: torch.Size([128])
param size: torch.Size([256, 128, 3, 3])
param size: torch.Size([256])
param size: torch.Size([256])
param size: torch.Size([256, 256, 3, 3])
param size: torch.Size([256])
param size: torch.Size([256])
param size: torch.Size([256, 128, 1, 1])
param size: torch.Size([256])
param size: torch.Size([256])
param size: torch.Size([256, 256, 3, 3])
param size: torch.Size([256])
param size: torch.Size([256])
param size: torch.Size([256, 256, 3, 3])
param size: torch.Size([256])
param size: torch.Size([256])
param size: torch.Size([512, 256, 3, 3])
param size: torch.Size([512])
param size: torch.Size([512])
param size: torch.Size([512, 512, 3, 3])
param size: torch.Size([512])
param size: torch.Size([512])
param size: torch.Size([512, 256, 1, 1])
param size: torch.Size([512])
param size: torch.Size([512])
param size: torch.Size([512, 512, 3, 3])
param size: torch.Size([512])
param size: torch.Size([512])
param size: torch.Size([512, 512, 3, 3])
param size: torch.Size([512])
param size: torch.Size([512])
param size: torch.Size([10, 512])
param size: torch.Size([10])



# MLP
layer name: feature.0.weight
layer name: feature.0.bias
layer name: feature.2.weight
layer name: feature.2.bias
layer name: feature.4.weight
layer name: feature.4.bias
layer name: classifier.weight
layer name: classifier.bias

param size: torch.Size([100, 2352])
param size: torch.Size([100])
param size: torch.Size([100, 100])
param size: torch.Size([100])
param size: torch.Size([100, 100])
param size: torch.Size([100])
param size: torch.Size([10, 100])
param size: torch.Size([10])







## Working Code of Cosine 
#-------------------------------------------------------#
#-------------------------------------------------------#
def calculate_cosine_similarity_loss(model_b, model_d, layer_names):
    cosine_loss = 0.0
    for name1, param1 in model_b.named_parameters():
        for layer_name in layer_names:
            if layer_name in name1:
                name2 = name1.replace(layer_name, layer_name.replace('features', 'classifier'))
                param2 = model_d.state_dict()[name2]
                if param1 is not None and param2 is not None and 'weight' in name1:
                    weight1 = param1.view(param1.size(0), -1)
                    weight2 = param2.view(param2.size(0), -1)
                    cosine_similarity = F.cosine_similarity(weight1, weight2)
                    cosine_loss += 1 - cosine_similarity
                    print(f'cosine_loss: {cosine_loss}')
    return cosine_loss
#-------------------------------------------------------#
#-------------------------------------------------------#
